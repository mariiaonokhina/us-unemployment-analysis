{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2bb7f61-786e-4696-acba-9fcf79981b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\"A value is trying to be set on a copy of a slice from a DataFrame\")\n",
    "warnings.filterwarnings('ignore', category=UserWarning) \n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6a69e0-e242-41a5-83ee-fb17384e92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dir: ./rawdata/oews/\n",
      "output dir: ./data/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DIR = './rawdata/oews/'\n",
    "OUTPUT_DIR = './data/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"input dir: {INPUT_DIR}\")\n",
    "print(f\"output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05059d5d-cd0a-4fb6-b8e0-0bb8ed782ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wage_cols = [\n",
    "    'TOT_EMP', 'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', \n",
    "    'H_MEAN', 'A_MEAN', 'MEAN_PRSE', \n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90',\n",
    "    'A_PCT10', 'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90'\n",
    "]\n",
    "def process_oews_data(file_path):\n",
    "    \"\"\"read single OEWS files，extract year，and pre-cleaning dataset\"\"\"\n",
    "    try:\n",
    "        #extract year from file name\n",
    "        year = int(os.path.basename(file_path).split('_')[-1].replace('.xlsx', ''))\n",
    "        df = pd.read_excel(file_path)\n",
    "        #drop all na rows\n",
    "        df.dropna(how='all', inplace=True)\n",
    "    \n",
    "        # cleaning: sussitute all non-numeric data-> NaN\n",
    "        # BLS dataset contains：'#', '**', '*' in rows as values for privacy/insufficient data etc\n",
    "        symbols_to_replace = ['#', '**', '*']\n",
    "        for col in df.columns:\n",
    "            if col in wage_cols:\n",
    "                df[col] = df[col].replace(symbols_to_replace, np.nan)\n",
    "        for col in wage_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        boolean_cols = ['ANNUAL', 'HOURLY']\n",
    "        for col in boolean_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).str.lower().map({'true': True, 'false': False, '1': True, '0': False, '': False})\n",
    "        if 'AREA' in df.columns:\n",
    "            df['AREA'] = pd.to_numeric(df['AREA'], errors='coerce').astype('Int64')\n",
    "            \n",
    "        # add new column:year\n",
    "        df['YEAR'] = year\n",
    "        selected_cols = [\n",
    "            'YEAR', 'AREA', 'AREA_TITLE', 'PRIM_STATE', \n",
    "            'NAICS', 'NAICS_TITLE', 'OCC_CODE', 'OCC_TITLE', \n",
    "            'TOT_EMP', 'A_MEAN', 'A_MEDIAN', 'A_PCT10', 'A_PCT90', \n",
    "            'ANNUAL', 'HOURLY' \n",
    "        ]\n",
    "        final_cols = [col for col in selected_cols if col in df.columns]\n",
    "        return df[final_cols]\n",
    "    except Exception as e:\n",
    "        print(f\"error when processing file: {file_path} : {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2eb52f-efe8-4a58-b509-add6c33b2aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files need to be processed...\n",
      "successfully combined 9 files. Total records: 3727879\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "# batch reading and combine\n",
    "all_files = glob.glob(os.path.join(INPUT_DIR, 'all_data_M_20*.xlsx'))\n",
    "print(f\"Found {len(all_files)} files need to be processed...\")\n",
    "\n",
    "all_data = [process_oews_data(f) for f in all_files]\n",
    "all_data = [df for df in all_data if df is not None]\n",
    "if all_data:\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"successfully combined {len(all_data)} files. Total records: {len(df_combined)}\")\n",
    "else:\n",
    "    print(\"!!!!error:check file path\")\n",
    "    df_combined = pd.DataFrame() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05df0c97-ae17-49d2-87b6-052a1c2e49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total records after cleaning: 639953\n",
      "\n",
      " sample data:\n",
      "      YEAR  AREA AREA_TITLE PRIM_STATE   NAICS  \\\n",
      "1404  2021    99       U.S.         US  000001   \n",
      "1405  2021    99       U.S.         US  000001   \n",
      "1408  2021    99       U.S.         US  000001   \n",
      "1409  2021    99       U.S.         US  000001   \n",
      "1410  2021    99       U.S.         US  000001   \n",
      "\n",
      "                                 NAICS_TITLE OCC_CODE  \\\n",
      "1404  Cross-industry, private ownership only  11-0000   \n",
      "1405  Cross-industry, private ownership only  11-1000   \n",
      "1408  Cross-industry, private ownership only  11-1020   \n",
      "1409  Cross-industry, private ownership only  11-1021   \n",
      "1410  Cross-industry, private ownership only  11-2000   \n",
      "\n",
      "                                              OCC_TITLE    TOT_EMP    A_MEAN  \\\n",
      "1404                             Management Occupations  7754600.0  125450.0   \n",
      "1405                                     Top Executives  3006050.0  121360.0   \n",
      "1408                    General and Operations Managers  2839990.0  115030.0   \n",
      "1409                    General and Operations Managers  2839990.0  115030.0   \n",
      "1410  Advertising, Marketing, Promotions, Public Rel...   820940.0  145870.0   \n",
      "\n",
      "      A_MEDIAN  A_PCT10  A_PCT90 ANNUAL HOURLY  \n",
      "1404  102780.0  47510.0      NaN    NaN    NaN  \n",
      "1405   98500.0  43040.0      NaN    NaN    NaN  \n",
      "1408   97430.0  41320.0      NaN    NaN    NaN  \n",
      "1409   97430.0  41320.0      NaN    NaN    NaN  \n",
      "1410  128480.0  63280.0      NaN    NaN    NaN  \n",
      "\n",
      " info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 639953 entries, 1404 to 3493866\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   YEAR         639953 non-null  int64  \n",
      " 1   AREA         639953 non-null  Int64  \n",
      " 2   AREA_TITLE   639953 non-null  object \n",
      " 3   PRIM_STATE   639953 non-null  object \n",
      " 4   NAICS        639953 non-null  object \n",
      " 5   NAICS_TITLE  639953 non-null  object \n",
      " 6   OCC_CODE     639953 non-null  object \n",
      " 7   OCC_TITLE    639953 non-null  object \n",
      " 8   TOT_EMP      639953 non-null  float64\n",
      " 9   A_MEAN       639951 non-null  float64\n",
      " 10  A_MEDIAN     639953 non-null  float64\n",
      " 11  A_PCT10      639953 non-null  float64\n",
      " 12  A_PCT90      613176 non-null  float64\n",
      " 13  ANNUAL       11704 non-null   object \n",
      " 14  HOURLY       0 non-null       object \n",
      "dtypes: Int64(1), float64(5), int64(1), object(8)\n",
      "memory usage: 78.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_combined.copy()\n",
    "\n",
    "# filtering\n",
    "# filter out rows with'00-0000': 'All Occupations'\n",
    "df_filtered = df_filtered[df_filtered['OCC_CODE'] != '00-0000']\n",
    "    \n",
    "# filter out rows'000000': 'Cross-industry' or 'All Industry'\n",
    "df_filtered = df_filtered[df_filtered['NAICS'] != '000000']\n",
    "\n",
    "# cleaning rigion data :filtering rows where PRIM_STATE = na\n",
    "df_filtered.dropna(subset=['PRIM_STATE'], inplace=True)\n",
    "\n",
    "# filter out when key column has na vals (TOT_EMP and A_MEDIAN)\n",
    "df_filtered.dropna(subset=['TOT_EMP', 'A_MEDIAN'], inplace=True)\n",
    "    \n",
    "\n",
    "for col in ['TOT_EMP', 'A_MEAN', 'A_MEDIAN']:\n",
    "    if col in df_filtered.columns:\n",
    "        df_filtered[col] = df_filtered[col].astype(float)\n",
    "    \n",
    "print(f\"total records after cleaning: {len(df_filtered)}\")\n",
    "    \n",
    "\n",
    "print(\"\\n sample data:\")\n",
    "print(df_filtered.head())\n",
    "print(f\"\\n info:\")\n",
    "print(df_filtered.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c581706-6141-4a2d-b62a-a355db8c08b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800a0bc-50e9-425b-a4cb-beeda91a71e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
